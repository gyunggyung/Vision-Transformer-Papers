<h1 align="center"> ğŸŒŸ Vision-Transformer-Papers ğŸŒŸ </h1>

<p align="center">
  </a> 
    </a>
  <em>
    Image Classification
    Â· Semantic Segmentation
  </em>
  <br />
  <em>
    Object Detection
    Â· General Classification
  </em>
  <br />
  <em>
     Fine-Grained Image Classification
     Â·  Depth Estimation
  </em>
  <br />
  <em>
    Instance Segmentation	
    Â· Salient Object Detection
    Â· Person Re-Identification	
  </em>
  <br />
  
  <em>
    <a href="https://github.com/gyunggyung/PyTorch">
      GOTO PyTorch!
    </a>
  </em>
</p>

<p align="center">
  <a href="https://opensource.org/licenses/MIT">
    <img alt="licenses" src="https://img.shields.io/github/license/gyunggyung/Vision-Transformer-Papers?style=flat-square"></a>
  <a href="https://github.com/gyunggyung/Vision-Transformer-Papers/stargazers">
    <img alt="GitHub stars" src="https://img.shields.io/github/stars/gyunggyung/Vision-Transformer-Papers?style=flat-square&color=yellow"></a>
  <a href="https://github.com/gyunggyung/Vision-Transformer-Papers/blob/master/watchers">
    <img alt="GitHub watching" src="https://img.shields.io/github/watchers/gyunggyung/Vision-Transformer-Papers?style=flat-square&color=ff69b4"></a>
  <a href="https://github.com/gyunggyung/Vision-Transformer-Papers/graphs/contributors">
    <img alt="contributors" src="https://img.shields.io/badge/contributors-welcome-yellowgreen?style=flat-square"></a>
</p>

<div align="center">
    <sub> Let's find out the latest and various Vision-Transformer-related papers. ğŸ™‡â€â™‚ï¸ğŸ™‡â€â™€ï¸ by <a href="https://github.com/gyunggyung/Vision-Transformer-Papers/stargazers">Stargazers</a>  </sub>
</div>


## Papers

- [2020/10] **[An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale](https://arxiv.org/abs/2010.11929v2.pdf)**    
- [2019/08] **[VISUALBERT: A SIMPLE AND PERFORMANT BASELINE FOR VISION AND LANGUAGE](https://arxiv.org/abs/2010.11929v2.pdf)** : *VISUALBERT*


## Reference
- https://huggingface.co/transformers/model_doc/vit.html
- https://paperswithcode.com/method/vision-transformer
- https://github.com/gyunggyung/NLP-Papers
